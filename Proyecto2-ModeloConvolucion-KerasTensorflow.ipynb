{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelo Convolusión 2D - Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importación de librerias para la generación del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.image as mpimg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications.xception import preprocess_input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Se cargan los datos del csv de las imágenes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('boneage-training-dataset.csv')\n",
    "test_df = pd.read_csv('boneage-test-dataset.csv')\n",
    "\n",
    "train_df['id'] = train_df['id'].apply(lambda x: str(x)+'.png')\n",
    "train_df['gender'] = train_df['male'].apply(lambda x: 'male' if x else 'female')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Se separa el training data en Training y Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train, df_valid = train_test_split(train_df, test_size = 0.2, random_state = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Se preparan los sets para las imagenes para Train, Validation y Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 10088 validated image filenames.\n",
      "Found 2523 validated image filenames.\n",
      "Found 200 images belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "img_size = 256\n",
    "\n",
    "train_data_generator = ImageDataGenerator(preprocessing_function = preprocess_input)\n",
    "val_data_generator = ImageDataGenerator(preprocessing_function = preprocess_input)\n",
    "\n",
    "train_generator = train_data_generator.flow_from_dataframe(\n",
    "    dataframe = df_train, directory = 'boneage-training-dataset/boneage-training-dataset',\n",
    "    x_col= 'id', y_col= 'boneage', batch_size = 32, seed = 42,\n",
    "    shuffle = True, class_mode= 'raw', flip_vertical = True,\n",
    "    color_mode = 'rgb', target_size = (img_size, img_size))\n",
    "\n",
    "validation_generator = val_data_generator.flow_from_dataframe(\n",
    "    dataframe = df_valid, directory = 'boneage-training-dataset/boneage-training-dataset',\n",
    "    x_col= 'id', y_col= 'boneage', batch_size = 32, seed = 42,\n",
    "    shuffle = True, class_mode= 'raw', flip_vertical = True,\n",
    "    color_mode = 'rgb', target_size = (img_size, img_size))\n",
    "\n",
    "test_data_generator = ImageDataGenerator(preprocessing_function = preprocess_input)\n",
    "\n",
    "test_generator = test_data_generator.flow_from_directory(\n",
    "    directory = 'boneage-test-dataset',\n",
    "    shuffle = False, \n",
    "    class_mode = None,\n",
    "    color_mode = 'rgb',\n",
    "    target_size = (img_size,img_size))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Se valida la existencia de las imagenes y se transforman a modo de prueba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2523 validated image filenames.\n"
     ]
    }
   ],
   "source": [
    "test_X, test_Y = next(val_data_generator.flow_from_dataframe( \n",
    "                            dataframe = df_valid, directory = 'boneage-training-dataset/boneage-training-dataset',\n",
    "                            x_col = 'id', y_col = 'boneage', \n",
    "                            target_size = (img_size, img_size),\n",
    "                            batch_size = 2523,\n",
    "                            class_mode = 'raw'\n",
    "                            ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generación del modelo y entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-9-5e2347e9abaf>:20: Model.fit_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use Model.fit, which supports generators.\n",
      "Epoch 1/15\n",
      "315/315 [==============================] - 513s 2s/step - loss: 1902.3429 - mse: 1902.3429 - val_loss: 1554.5613 - val_mse: 1554.5613\n",
      "Epoch 2/15\n",
      "315/315 [==============================] - 458s 1s/step - loss: 1398.3236 - mse: 1398.3236 - val_loss: 1352.3217 - val_mse: 1352.3217\n",
      "Epoch 3/15\n",
      "315/315 [==============================] - 457s 1s/step - loss: 1308.8787 - mse: 1308.8787 - val_loss: 1238.8737 - val_mse: 1238.8737\n",
      "Epoch 4/15\n",
      "315/315 [==============================] - 459s 1s/step - loss: 1119.1768 - mse: 1119.1768 - val_loss: 1193.6454 - val_mse: 1193.6454\n",
      "Epoch 5/15\n",
      "315/315 [==============================] - 458s 1s/step - loss: 985.6346 - mse: 985.6346 - val_loss: 1133.5321 - val_mse: 1133.5321\n",
      "Epoch 6/15\n",
      "315/315 [==============================] - 457s 1s/step - loss: 923.0568 - mse: 923.0568 - val_loss: 1529.7722 - val_mse: 1529.7722\n",
      "Epoch 7/15\n",
      "315/315 [==============================] - 455s 1s/step - loss: 835.0329 - mse: 835.0329 - val_loss: 1057.5525 - val_mse: 1057.5525\n",
      "Epoch 8/15\n",
      "315/315 [==============================] - 467s 1s/step - loss: 751.4699 - mse: 751.4699 - val_loss: 1117.3898 - val_mse: 1117.3898\n",
      "Epoch 9/15\n",
      "315/315 [==============================] - 458s 1s/step - loss: 654.7030 - mse: 654.7030 - val_loss: 1157.9514 - val_mse: 1157.9514\n",
      "Epoch 10/15\n",
      "315/315 [==============================] - 495s 2s/step - loss: 602.2787 - mse: 602.2787 - val_loss: 1076.2018 - val_mse: 1076.2018\n",
      "Epoch 11/15\n",
      "315/315 [==============================] - 587s 2s/step - loss: 514.0380 - mse: 514.0380 - val_loss: 1078.7229 - val_mse: 1078.7229\n",
      "Epoch 12/15\n",
      "315/315 [==============================] - 647s 2s/step - loss: 454.8170 - mse: 454.8170 - val_loss: 1108.0093 - val_mse: 1108.0093\n",
      "Epoch 13/15\n",
      "315/315 [==============================] - 646s 2s/step - loss: 383.7400 - mse: 383.7400 - val_loss: 1101.1716 - val_mse: 1101.1716\n",
      "Epoch 14/15\n",
      "315/315 [==============================] - 629s 2s/step - loss: 325.5528 - mse: 325.5528 - val_loss: 1115.9220 - val_mse: 1115.9220\n",
      "Epoch 15/15\n",
      "315/315 [==============================] - 632s 2s/step - loss: 272.4796 - mse: 272.4796 - val_loss: 1150.7793 - val_mse: 1150.7793\n"
     ]
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, Conv2D, Dropout\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "# Input Layer\n",
    "model.add(Conv2D(16, kernel_size=(7,7), strides=(2,2), activation='relu', input_shape=(img_size, img_size, 3)))\n",
    "# Convulotional Layers\n",
    "model.add(Conv2D(32, kernel_size=(5,5), strides=(2,2), activation='relu'))\n",
    "# Flattening\n",
    "model.add(Flatten())\n",
    "# Dense Layer\n",
    "model.add(Dense(10, activation='relu'))\n",
    "model.add(Dense(1, activation='linear'))\n",
    "model.compile(loss='mean_squared_error', optimizer='adam', metrics=['mse'])\n",
    "\n",
    "STEP_SIZE_TRAIN=train_generator.n//train_generator.batch_size\n",
    "STEP_SIZE_VALID=validation_generator.n//validation_generator.batch_size\n",
    "history = model.fit_generator(generator=train_generator,\n",
    "                    steps_per_epoch=STEP_SIZE_TRAIN,\n",
    "                    validation_data=validation_generator,\n",
    "                    validation_steps=STEP_SIZE_VALID,\n",
    "                    epochs=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generación de las predicciones con el set de validación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(validation_generator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Se realiza una validación para revisar que tan bien funcionó el modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Edad Osea de la predicción: 179.60643 años\n",
      "Edad Osea real: 94 años\n"
     ]
    }
   ],
   "source": [
    "print(\"Edad Osea de la predicción:\",predictions[0][0],\"años\")\n",
    "print(\"Edad Osea real:\",df_valid['boneage'].iloc[0],\"años\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
